{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufbkcme55nMb"
      },
      "source": [
        "# Project : Text To AI Image Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WshfsRgbvyPr"
      },
      "source": [
        "**AI Image Generator with Stable Diffusion**\n",
        "\n",
        "\n",
        "This is a simple and powerful AI image generation web app built using Hugging Face's diffusers library and deployed on Gradio + Hugging Face Spaces.\n",
        "\n",
        "It uses **Stable Diffusion v1.5** to generate* high-quality images *from text prompts given by the user.\n",
        "\n",
        "-------------------------------------------------------------------------\n",
        "\n",
        " **Features**\n",
        "\n",
        " Text-to-Image generation using Stable Diffusion\n",
        "\n",
        " Clean and simple web interface via Gradio\n",
        "\n",
        " Fast image generation with GPU support (CUDA)\n",
        "\n",
        " Fully deployable and shareable via Hugging Face Spaces\n",
        "\n",
        " ------------------------------------------------------------------------\n",
        "\n",
        " **Demo**\n",
        "\n",
        " Try it here: https://<your-space-name>.huggingface.space\n",
        "(Replace with your actual Hugging Face Space URL)\n",
        "\n",
        " How It Works\n",
        "User enters a text prompt (e.g., \"a cat sitting on the moon\").\n",
        "\n",
        "The backend runs Stable Diffusion to convert text into an image.\n",
        "\n",
        "The output image is displayed on the web interface in seconds.\n",
        "\n",
        " Requirements\n",
        "These packages are required (also saved in requirements.txt):\n",
        "\n",
        "\n",
        "1.   Txt\n",
        "2.   Copy\n",
        "3.   Edit\n",
        "4.   Diffusers\n",
        "5.   Transformers\n",
        "6.   Accelerate\n",
        "7.   Safetensors\n",
        "8.   Torch\n",
        "9.   Gradio\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvuJgxcT0ceK"
      },
      "source": [
        "\n",
        "\n",
        "-------------------------------------------------------------------------\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsTvrbZst1E6"
      },
      "source": [
        "# Step 1: Installed and upgraded essential Hugging Face libraries\n",
        "\n",
        "Diffusers\n",
        "\n",
        "*   Diffusers\n",
        "*   Transformers\n",
        "*   Accelerate\n",
        "*   Safetensors\n",
        "\n",
        "\n",
        "\n",
        "These core libraries were updated to their latest stable versions to support advanced capabilities such as text generation, text-to-image synthesis, and optimized model execution. Safetensors ensures secure and efficient loading of model weights, contributing to faster and more reliable performance across the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 38273,
          "status": "ok",
          "timestamp": 1754148274008,
          "user": {
            "displayName": "Apoorv Srivastava",
            "userId": "04251241414074510436"
          },
          "user_tz": -330
        },
        "id": "yHBED87ABzu8",
        "outputId": "ce3ca1ce-fda2-45e6-9d70-2c27ec30c66e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: diffusers in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.34.0)\n",
            "Requirement already satisfied: transformers in /usr/local/python/3.12.1/lib/python3.12/site-packages (4.54.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.9.0)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/python/3.12.1/lib/python3.12/site-packages (from diffusers) (8.7.0)\n",
            "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from diffusers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.27.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from diffusers) (0.34.3)\n",
            "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.12/site-packages (from diffusers) (2.3.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from diffusers) (2025.7.34)\n",
            "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from diffusers) (2.32.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from diffusers) (0.5.3)\n",
            "Requirement already satisfied: Pillow in /home/codespace/.local/lib/python3.12/site-packages (from diffusers) (11.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.27.0->diffusers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.27.0->diffusers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from huggingface-hub>=0.27.0->diffusers) (1.1.5)\n",
            "Requirement already satisfied: psutil in /home/codespace/.local/lib/python3.12/site-packages (from accelerate) (7.0.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from accelerate) (2.7.1+cpu)\n",
            "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from importlib_metadata->diffusers) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->diffusers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests->diffusers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->diffusers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests->diffusers) (2025.7.9)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: safetensors in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.5.3)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install --upgrade diffusers transformers accelerate\n",
        "!pip install safetensors\n",
        "!pip install gradio --quiet\n",
        "!pip install diffusers transformers accelerate safetensors gradio --quiet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTiP1pFEGJCe"
      },
      "source": [
        "----------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSFaiDRP00Fa"
      },
      "source": [
        "# **Step 2:** Importing Important Libraries & Logging in Hugging Face\n",
        "\n",
        "Used an authentication token to enable secure access to Hugging Face-hosted models and resources.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "executionInfo": {
          "elapsed": 8,
          "status": "ok",
          "timestamp": 1754148274025,
          "user": {
            "displayName": "Apoorv Srivastava",
            "userId": "04251241414074510436"
          },
          "user_tz": -330
        },
        "id": "b46vOtysCSqn"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import gradio as gr\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from huggingface_hub import login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQoYjtogGPyl"
      },
      "source": [
        "-----------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DC6kvm51OZj"
      },
      "source": [
        "# Step 3: Authenticate with Hugging Face to enable loading of the Stable Diffusion v1.5 model for text-to-image generation in later steps.\n",
        "\n",
        "*  Utilized StableDiffusionPipeline from the diffusers library to load the pretrained Stable Diffusion v1.5 model for text-to-image generation.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "executionInfo": {
          "elapsed": 17,
          "status": "ok",
          "timestamp": 1754148274086,
          "user": {
            "displayName": "Apoorv Srivastava",
            "userId": "04251241414074510436"
          },
          "user_tz": -330
        },
        "id": "Q72XjYIXCeuz"
      },
      "outputs": [],
      "source": [
        "# Step 3: Authenticate with Hugging Face\n",
        "login(\"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\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obmLwpoTGUn-"
      },
      "source": [
        "-----------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRsXBWn01dHb"
      },
      "source": [
        "\n",
        "# Step 4: Generate Image from Prompt\n",
        "*  The user provides a descriptive text prompt, which is processed by the model to generate a corresponding high-quality image.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371,
          "referenced_widgets": [
            "bdffc47b15d6425683073345f8e0ce4b",
            "8d95b94edcee45f68ae912a879dfb95b",
            "79329f5e706c42249236b5f6a99dd132",
            "f42d0acd7f4647d291ec1a433b54c233",
            "5806945d26bc46f1b17a61473c17f6a9",
            "339aa8d6aee64360a45d562a49504efa",
            "101c2cef4ad142b298c31eef291a7ce3",
            "e8af81f321a44c2bb99620d6a19c3d29",
            "3a5df2e0da8448c99f4d626249759e05",
            "bdaabe4e22d74b0eb2bdae2977d27b56",
            "e889c7a6993042989316f34445456fce"
          ]
        },
        "executionInfo": {
          "elapsed": 42139,
          "status": "error",
          "timestamp": 1754148316230,
          "user": {
            "displayName": "Apoorv Srivastava",
            "userId": "04251241414074510436"
          },
          "user_tz": -330
        },
        "id": "rAu1JzAlCmWS",
        "outputId": "0f0ca2af-e554-49b9-9fba-7c77eb2cd0ad"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading pipeline components...: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:32<00:00,  4.62s/it]\n",
            "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
            "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
            "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
            "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n"
          ]
        }
      ],
      "source": [
        "#  Step 4: Load the pipeline\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    \"runwayml/stable-diffusion-v1-5\",\n",
        "    torch_dtype=torch.float16,\n",
        "    use_safetensors=True\n",
        ")\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "pipe = pipe.to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhZWR_FoGWnl"
      },
      "source": [
        "-----------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_btHClz1qcz"
      },
      "source": [
        "# **Step 5:** Display Image\n",
        "\n",
        "*   Displayed the image using matplotlib:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "executionInfo": {
          "elapsed": 153,
          "status": "aborted",
          "timestamp": 1754148316313,
          "user": {
            "displayName": "Apoorv Srivastava",
            "userId": "04251241414074510436"
          },
          "user_tz": -330
        },
        "id": "OBxilsZxCpBZ"
      },
      "outputs": [],
      "source": [
        "def generate_image(prompt):\n",
        "    print(\" Prompt received:\", prompt)\n",
        "    try:\n",
        "        image = pipe(prompt).images[0]\n",
        "        print(\"Image generated successfully\")\n",
        "        return image\n",
        "    except Exception as e:\n",
        "        print(\" Error in generating image:\", str(e))  # Yeh sabse important line hai\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmdP7EZuGYOd"
      },
      "source": [
        "-----------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTvvFHty2HmL"
      },
      "source": [
        "# Step 6: Building the Web Interface\n",
        "Why Gradio?\n",
        "\n",
        "* Gradio offers a streamlined and efficient framework for rapidly developing interactive web interfaces tailored for machine learning models, enabling seamless user interaction without extensive frontend development.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "executionInfo": {
          "elapsed": 1,
          "status": "aborted",
          "timestamp": 1754148316317,
          "user": {
            "displayName": "Apoorv Srivastava",
            "userId": "04251241414074510436"
          },
          "user_tz": -330
        },
        "id": "0oDH_0BBCz-Y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7863\n",
            "\n",
            "Could not create share link. Missing file: /home/codespace/.cache/huggingface/gradio/frpc/frpc_linux_amd64_v0.3. \n",
            "\n",
            "Please check your internet connection. This can happen if your antivirus software blocks the download of this file. You can install manually by following these steps: \n",
            "\n",
            "1. Download this file: https://cdn-media.huggingface.co/frpc-gradio-0.3/frpc_linux_amd64\n",
            "2. Rename the downloaded file to: frpc_linux_amd64_v0.3\n",
            "3. Move the file to this location: /home/codespace/.cache/huggingface/gradio/frpc\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Gradio UI\n",
        "demo = gr.Interface(\n",
        "    fn=generate_image,\n",
        "    inputs=gr.Textbox(label=\"Enter your image prompt\"),\n",
        "    outputs=gr.Image(type=\"pil\"),\n",
        "    title=\"Stable Diffusion Generator\",\n",
        "    description=\"Enter any creative prompt and get an AI-generated image!\"\n",
        ")\n",
        "\n",
        "# Launch UI\n",
        "demo.launch(share=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO2HVZvVGgBl"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUVqS85cHnF9"
      },
      "source": [
        "# Possible Challenges I Encountered\n",
        "# 1. Environment and Dependency Conflicts\n",
        "Installing large libraries such as diffusers, transformers, torch, and safetensors can be time-consuming and may lead to version incompatibilities.\n",
        "\n",
        "\n",
        "Frequent updates in Hugging Face libraries can result in breaking changes or deprecations.\n",
        "\n",
        "Compatibility issues between PyTorch and CUDA (e.g., incorrect torch_dtype or mismatched CUDA versions).\n",
        "\n",
        "Long installation times and memory-related errors, especially on platforms like Google Colab with limited RAM/VRAM.\n",
        "\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n",
        "\n",
        "\n",
        "--------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "# 2. Authentication with Hugging Face Issues related to token usage, such as:\n",
        "\n",
        "Expired or invalid tokens\n",
        "\n",
        "Incorrect token scope (e.g., requiring write access but using a read-only token)\n",
        "\n",
        "Calling login() without an active internet connection or in an incorrect sequence\n",
        "\n",
        "\n",
        "--------------------------------------------------------------------------------\n",
        "\n",
        "# 3. Errors During Model Loading Common problems while initializing StableDiffusionPipeline:\n",
        "\n",
        "Setting use_safetensors=True when the model does not support safetensors\n",
        "\n",
        "Using torch_dtype=torch.float16 on CPUs, which only support float32\n",
        "\n",
        "Running the pipeline without GPU access (e.g., on Colab's free tier), resulting in performance bottlenecks or crashes\n",
        "\n",
        "\n",
        "--------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "# 4. Failures in Image Generation Input prompts that are too long, too short, or malformed can cause .images[0] to fail\n",
        "\n",
        "Delays or timeouts caused by limited GPU resources or slow Hugging Face model server response\n",
        "\n",
        "Output not rendered as expected \u2014 occasionally producing blank, distorted, or corrupt images\n",
        "\n",
        "--------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "# 5. Challenges in Debugging and Exception Handling Lack of descriptive error messages can hinder effective troubleshooting\n",
        "\n",
        "Although try/except blocks are helpful, capturing and printing full tracebacks would offer better insights during development\n",
        "\n",
        "--------------------------------------------------------------------------------\n",
        "\n",
        "# 6. Difficulties in Gradio Deployment Connectivity issues during demo.launch(share=True) may prevent the interface from launching\n",
        "\n",
        "Gradio UI responsiveness can degrade in Colab environments\n",
        "\n",
        "Frequent disconnections or timeouts in Colab sessions interrupt testing and development\n",
        "\n",
        "Deploying to Hugging Face Spaces requires additional setup, such as GitHub integration and creating a model card\n",
        "\n",
        "--------------------------------------------------------------------------------\n",
        "\n",
        "# 7. Hardware Constraints (Google Colab) Hitting the free GPU quota limit restricts further usage\n",
        "\n",
        "Out-of-memory (OOM) errors when using high-resolution or multiple prompts\n",
        "\n",
        "Colab runtime disconnects after periods of inactivity, interrupting ongoing processes\n",
        "\n",
        "--------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "# 8. Gaps in Performance and User Experience No progress indicator during image generation, leaving the user uncertain about runtime status\n",
        "\n",
        "Lack of input validation \u2014 empty or incorrect prompts can break the generation pipeline\n",
        "\n",
        "Output image display is basic, without metadata, download options, or customization features\n",
        "\n",
        "--------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "# 9. Security and Content Moderation Issues Hardcoded access tokens in notebooks pose serious security risks\n",
        "\n",
        "Open-ended text input enables misuse for generating inappropriate or unsafe content\n",
        "\n",
        "Omitting safety_checker may result in NSFW or offensive outputs without filtering\n",
        "\n",
        "--------------------------------------------------------------------------------\n",
        "\n",
        "# 10. Missing Functional Enhancements No built-in prompt history or image storage mechanism\n",
        "\n",
        "Lack of configurable options such as image resolution, style, or batch generation\n",
        "\n",
        "No functionality for users to download or save generated images within the interface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SVzm3_9cPqb"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}